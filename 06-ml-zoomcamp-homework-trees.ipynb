{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import Markdown as md\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n#from sklearn.linear_model import LogisticRegression\n#from sklearn.metrics import auc as sklearn_auc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction import DictVectorizer\n","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:01.071950Z","iopub.execute_input":"2021-10-16T17:14:01.072736Z","iopub.status.idle":"2021-10-16T17:14:02.086078Z","shell.execute_reply.started":"2021-10-16T17:14:01.072696Z","shell.execute_reply":"2021-10-16T17:14:02.085189Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import shelve\nsavefile = 'Savefile.sav'","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:20:29.308270Z","iopub.execute_input":"2021-10-16T17:20:29.308590Z","iopub.status.idle":"2021-10-16T17:20:29.314313Z","shell.execute_reply.started":"2021-10-16T17:20:29.308556Z","shell.execute_reply":"2021-10-16T17:20:29.313375Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"- Homework source https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/course-zoomcamp/06-trees/homework.md\n- Lecture https://github.com/alexeygrigorev/mlbookcamp-code/blob/master/chapter-06-trees/06-trees.ipynb\n\n## 6.10 Homework\n\nThe goal of this homework is to create a tree-based regression model for prediction apartment prices (column `'price'`).\n\nIn this homework we'll again use the New York City Airbnb Open Data dataset - the same one we used in homework 2 and 3.\n\nYou can take it from [Kaggle](https://www.kaggle.com/dgomonov/new-york-city-airbnb-open-data?select=AB_NYC_2019.csv)\nor download from [here](https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AB_NYC_2019.csv)\nif you don't want to sign up to Kaggle.\n\n\nFor this homework, we prepared a [starter notebook](homework-6-starter.ipynb). \n\n\n## Loading the data\n\n* Use only the following columns:\n    * `'neighbourhood_group',`\n    * `'room_type',`\n    * `'latitude',`\n    * `'longitude',`\n    * `'minimum_nights',`\n    * `'number_of_reviews','reviews_per_month',`\n    * `'calculated_host_listings_count',`\n    * `'availability_365',`\n    * `'price'`\n* Fill NAs with 0\n* Apply the log tranform to `price`\n* Do train/validation/test split with 60%/20%/20% distribution. \n* Use the `train_test_split` function and set the `random_state` parameter to 1\n* Use `DictVectorizer` to turn the dataframe into matrices","metadata":{}},{"cell_type":"code","source":"col = ['neighbourhood_group',\n    'room_type',\n    'latitude',\n    'longitude',\n    'minimum_nights',\n    'number_of_reviews','reviews_per_month',\n    'calculated_host_listings_count',\n    'availability_365',\n    'price']","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:02.089939Z","iopub.execute_input":"2021-10-16T17:14:02.090216Z","iopub.status.idle":"2021-10-16T17:14:02.094784Z","shell.execute_reply.started":"2021-10-16T17:14:02.090186Z","shell.execute_reply":"2021-10-16T17:14:02.093987Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"df = (\n pd.read_csv('../input/new-york-city-airbnb-open-data/AB_NYC_2019.csv')\n[col]\n.fillna(0)\n) \ndf['price'] = np.log1p(df['price'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:02.095905Z","iopub.execute_input":"2021-10-16T17:14:02.096160Z","iopub.status.idle":"2021-10-16T17:14:02.467027Z","shell.execute_reply.started":"2021-10-16T17:14:02.096132Z","shell.execute_reply":"2021-10-16T17:14:02.466120Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"y='price'\ntest=0.2\nval=0.2\nseed=1\n\ndf_train_full, df_test = train_test_split(df, test_size=test, random_state=seed)\ndf_train, df_val = train_test_split(df_train_full, test_size=val/(1-test), random_state=seed)\n\ny_test = df_test[y].copy().values\ny_val = df_val[y].copy().values\ny_train = df_train[y].copy().values\ndel df_test[y]\ndel df_val[y]\ndel df_train[y]","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:02.469039Z","iopub.execute_input":"2021-10-16T17:14:02.469470Z","iopub.status.idle":"2021-10-16T17:14:02.498846Z","shell.execute_reply.started":"2021-10-16T17:14:02.469430Z","shell.execute_reply":"2021-10-16T17:14:02.497955Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# hot encoding\ndict_train = df_train.to_dict(orient='records')\ndict_val = df_val.to_dict(orient='records')\ndv = DictVectorizer(sparse=False)\nX_train = dv.fit_transform(dict_train)\nX_val = dv.transform(dict_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:02.500043Z","iopub.execute_input":"2021-10-16T17:14:02.500296Z","iopub.status.idle":"2021-10-16T17:14:03.465435Z","shell.execute_reply.started":"2021-10-16T17:14:02.500265Z","shell.execute_reply":"2021-10-16T17:14:03.464647Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"## Question 1\n\nLet's train a decision tree regressor to predict the price variable. \n\n* Train a model with `max_depth=1`\n\n\nWhich feature is used for splitting the data?\n\n* `room_type`\n* `neighbourhood_group`\n* `number_of_reviews`\n* `reviews_per_month`","metadata":{}},{"cell_type":"code","source":"# https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\nfrom sklearn.tree import DecisionTreeRegressor","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:03.466348Z","iopub.execute_input":"2021-10-16T17:14:03.466566Z","iopub.status.idle":"2021-10-16T17:14:03.634432Z","shell.execute_reply.started":"2021-10-16T17:14:03.466541Z","shell.execute_reply":"2021-10-16T17:14:03.633671Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"dt = DecisionTreeRegressor(max_depth=1)\ndt.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:03.635519Z","iopub.execute_input":"2021-10-16T17:14:03.635758Z","iopub.status.idle":"2021-10-16T17:14:03.665730Z","shell.execute_reply.started":"2021-10-16T17:14:03.635729Z","shell.execute_reply":"2021-10-16T17:14:03.664845Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import export_text\nprint(export_text(dt, feature_names=dv.get_feature_names()))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:03.667077Z","iopub.execute_input":"2021-10-16T17:14:03.667397Z","iopub.status.idle":"2021-10-16T17:14:03.674081Z","shell.execute_reply.started":"2021-10-16T17:14:03.667357Z","shell.execute_reply":"2021-10-16T17:14:03.673100Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"from sklearn.tree import plot_tree\nplot_tree(dt, feature_names=dv.get_feature_names())\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:03.675564Z","iopub.execute_input":"2021-10-16T17:14:03.676629Z","iopub.status.idle":"2021-10-16T17:14:03.994028Z","shell.execute_reply.started":"2021-10-16T17:14:03.676481Z","shell.execute_reply":"2021-10-16T17:14:03.993234Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# first node\nfeature_id = dt.tree_.feature[0] # [12, -2, -2]\nfeature_name = dv.get_feature_names()[feature_id] # 'room_type=Entire home/apt'\nmd(f'### Which feature is used for splitting the data?: **{feature_name.split(\"=\")[0]}**')","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:03.996767Z","iopub.execute_input":"2021-10-16T17:14:03.997050Z","iopub.status.idle":"2021-10-16T17:14:04.004491Z","shell.execute_reply.started":"2021-10-16T17:14:03.997020Z","shell.execute_reply":"2021-10-16T17:14:04.003650Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Question 2\n\nTrain a random forest model with these parameters:\n\n* `n_estimators=10`\n* `random_state=1`\n* `n_jobs=-1`  (optional - to make training faster)\n\n\nWhat's the RMSE of this model on validation?\n\n* 0.059\n* 0.259\n* 0.459\n* 0.659","metadata":{}},{"cell_type":"code","source":"# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html?highlight=randomforest#sklearn.ensemble.RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\ndef get_rmse(y_pred, y_true):\n    mse = ((y_pred - y_true) ** 2).mean()\n    return np.sqrt(mse)\n#enddef","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:04.005993Z","iopub.execute_input":"2021-10-16T17:14:04.006386Z","iopub.status.idle":"2021-10-16T17:14:04.040524Z","shell.execute_reply.started":"2021-10-16T17:14:04.006342Z","shell.execute_reply":"2021-10-16T17:14:04.039706Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=10, random_state=1) # n_jobs=-1\nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:04.041725Z","iopub.execute_input":"2021-10-16T17:14:04.042018Z","iopub.status.idle":"2021-10-16T17:14:05.729063Z","shell.execute_reply.started":"2021-10-16T17:14:04.041980Z","shell.execute_reply":"2021-10-16T17:14:05.728243Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"md(f\"### What's the RMSE of this model on validation? : **{get_rmse(rf.predict(X_val), y_val):.4f}**\")\n# 0.4599","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:05.730288Z","iopub.execute_input":"2021-10-16T17:14:05.730534Z","iopub.status.idle":"2021-10-16T17:14:05.772144Z","shell.execute_reply.started":"2021-10-16T17:14:05.730505Z","shell.execute_reply":"2021-10-16T17:14:05.771356Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"## Question 3\n\nNow let's experiment with the `n_estimators` parameter\n\n* Try different values of this parameter from 10 to 200 with step 10\n* Set `random_state` to `1`\n* Evaluate the model on the validation dataset\n\n\nAfter which value of `n_estimators` does RMSE stop improving?\n\n- 10\n- 50\n- 70\n- 120","metadata":{}},{"cell_type":"code","source":"rmse_list = {}\nfor n in np.linspace(10,200,10).astype(int):\n    rf = RandomForestRegressor(n_estimators=n, random_state=1,n_jobs=-1) \n    rf.fit(X_train, y_train)\n    rmse_list[n] = get_rmse(rf.predict(X_val), y_val)\n    print(n,rmse_list[n])\n#endfor","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:14:05.773198Z","iopub.execute_input":"2021-10-16T17:14:05.773428Z","iopub.status.idle":"2021-10-16T17:15:14.528932Z","shell.execute_reply.started":"2021-10-16T17:14:05.773400Z","shell.execute_reply":"2021-10-16T17:15:14.527985Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"pd.Series(rmse_list).plot()\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:15:14.530263Z","iopub.execute_input":"2021-10-16T17:15:14.530606Z","iopub.status.idle":"2021-10-16T17:15:14.762269Z","shell.execute_reply.started":"2021-10-16T17:15:14.530563Z","shell.execute_reply":"2021-10-16T17:15:14.761489Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"### After which value of n_estimators does RMSE stop improving? **120**","metadata":{}},{"cell_type":"markdown","source":"## Question 4\n\nLet's select the best `max_depth`:\n\n* Try different values of `max_depth`: `[10, 15, 20, 25]`\n* For each of these values, try different values of `n_estimators` from 10 till 200 (with step 10)\n* Fix the random seed: `random_state=1`\n\n\n\nWhat's the best `max_depth`:\n\n* 10\n* 15\n* 20\n* 25","metadata":{}},{"cell_type":"code","source":"rmse_list02 = None\nwith shelve.open(savefile, 'c') as save: \n    k = 'rmse02'\n    if k not in save:\n        rmse_list02 = {}\n        for d in [10, 15, 20, 25]:\n            rmse_list02[d] = rmse_list02.get(d,{}) # create empty Dictionary if key doesn't exist yet\n            for n in np.linspace(10,200,10).astype(int):\n                if n not in rmse_list02[d]:\n                    rf = RandomForestRegressor(n_estimators=n\n                                               ,max_depth=d\n                                               ,random_state=1\n                                              ,n_jobs=-1) # \n                    rf.fit(X_train, y_train)\n                    rmse_list02[d][n] = get_rmse(rf.predict(X_val), y_val)\n                #endif\n                print(d,n,rmse_list02[d][n])\n            #endfor\n        #endfor\n        save[k]= rmse_list02\n    else:\n        rmse_list02 = save[k]\n    #endif\n#endwith","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-10-16T17:25:26.173890Z","iopub.execute_input":"2021-10-16T17:25:26.174186Z","iopub.status.idle":"2021-10-16T17:25:26.184213Z","shell.execute_reply.started":"2021-10-16T17:25:26.174155Z","shell.execute_reply":"2021-10-16T17:25:26.183288Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nfor d in [10, 15, 20, 25]:\n    x = rmse_list02[d].keys()\n    y = [rmse_list02[d][n] for n in x]\n    plt.plot(x, y, label=f'depth={d}')\n#endfor\nplt.xticks(range(0, 201, 10))\nplt.grid()\nplt.legend()\nplt.xlabel('n_estimators')\nplt.ylabel('rmse')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:25:57.163988Z","iopub.execute_input":"2021-10-16T17:25:57.164269Z","iopub.status.idle":"2021-10-16T17:25:57.440566Z","shell.execute_reply.started":"2021-10-16T17:25:57.164240Z","shell.execute_reply":"2021-10-16T17:25:57.439661Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"res = { min([rmse_list02[d][n] for n in rmse_list02[d]]) : d for d in rmse_list02 }\nmd(f\"### What's the best `max_depth`? : **{res[sorted(res)[0]]}**\") # 15","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:56.347590Z","iopub.execute_input":"2021-10-16T17:18:56.347801Z","iopub.status.idle":"2021-10-16T17:18:56.354671Z","shell.execute_reply.started":"2021-10-16T17:18:56.347776Z","shell.execute_reply":"2021-10-16T17:18:56.353899Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"markdown","source":"#### **Bonus question (not graded):**\n\nWill the answer be different if we change the seed for the model?\n\n**Answer**: it should *not*, since n_estimators is sufficently high (>100).","metadata":{}},{"cell_type":"markdown","source":"## Question 5\n\nWe can extract feature importance information from tree-based models. \n\nAt each step of the decision tree learning algorith, it finds the best split. \nWhen doint it, we can calculate \"gain\" - the reduction in impurity before and after the split. \nThis gain is quite useful in understanding what are the imporatant features \nfor tree-based models.\n\nIn Scikit-Learn, tree-based models contain this information in the\n[`feature_importances_`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor.feature_importances_)\nfield. \n\nFor this homework question, we'll find the most important feature:\n\n* Train the model with these parametes:\n    * `n_estimators=10`,\n    * `max_depth=20`,\n    * `random_state=1`,\n    * `n_jobs=-1` (optional)\n* Get the feature importance information from this model\n\n\nWhat's the most important feature? \n\n* `neighbourhood_group=Manhattan`\n* `room_type=Entire home/apt`\t\n* `longitude`\n* `latitude`","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor(n_estimators=10\n                           ,max_depth=20\n                           ,random_state=1\n                          ,n_jobs=-1) # \nrf.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:56.355895Z","iopub.execute_input":"2021-10-16T17:18:56.356112Z","iopub.status.idle":"2021-10-16T17:18:57.094980Z","shell.execute_reply.started":"2021-10-16T17:18:56.356086Z","shell.execute_reply":"2021-10-16T17:18:57.094297Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"importances = list(zip(dv.feature_names_, rf.feature_importances_))\ndf_importance = (\n    pd.DataFrame(importances, columns=['feature', 'gain'])\n#       [lambda x : x['gain'] > 0]\n     .sort_values(by='gain', ascending=False)\n)\nmd(f\"### What's the most important feature? : **{df_importance['feature'].iloc[0]}**\")\n# room_type=Entire home/apt","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:57.096070Z","iopub.execute_input":"2021-10-16T17:18:57.096766Z","iopub.status.idle":"2021-10-16T17:18:57.207659Z","shell.execute_reply.started":"2021-10-16T17:18:57.096732Z","shell.execute_reply":"2021-10-16T17:18:57.207040Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"## Question 6\n\nNow let's train an XGBoost model! For this question, we'll tune the `eta` parameter\n\n* Install XGBoost\n* Create DMatrix for train and validation\n* Create a watchlist\n* Train a model with these parameters for 100 rounds:\n\n```\nxgb_params = {\n    'eta': 0.3, \n    'max_depth': 6,\n    'min_child_weight': 1,\n    \n    'objective': 'reg:squarederror',\n    'nthread': 8,\n    \n    'seed': 1,\n    'verbosity': 1,\n}\n```\n\nNow change `eta` first to `0.1` and then to `0.01`\n\nWhat's the best eta?\n\n* 0.3\n* 0.1\n* 0.01","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb # Install XGBoost\ndef parse_xgb_output(output):\n    tree = []\n    p_train = []\n    p_val = []\n\n    for line in output.stdout.strip().split('\\n'):\n        it_line, train_line, val_line = line.split('\\t')\n\n        it = int(it_line.strip('[]'))\n        train = float(train_line.split(':')[1])\n        val = float(val_line.split(':')[1])\n\n        tree.append(it)\n        p_train.append(train)\n        p_val.append(val)\n\n    return tree, p_train, p_val\n#enddef","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:57.208713Z","iopub.execute_input":"2021-10-16T17:18:57.209589Z","iopub.status.idle":"2021-10-16T17:18:57.311394Z","shell.execute_reply.started":"2021-10-16T17:18:57.209544Z","shell.execute_reply":"2021-10-16T17:18:57.310627Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Create DMatrix for train and validation\ndtrain = xgb.DMatrix(X_train, label=y_train, feature_names=dv.feature_names_)\ndval = xgb.DMatrix(X_val, label=y_val, feature_names=dv.feature_names_)\n# Create a watchlist\nwatchlist = [(dtrain, 'train'), (dval, 'val')]\n# Train a model with these parameters for 100 rounds:\nxgb_params = {\n    'eta': 0.3, \n    'max_depth': 6,\n    'min_child_weight': 1,\n\n    'objective': 'reg:squarederror',\n    'nthread': 8,\n\n    'seed': 1,\n    'verbosity': 1,\n}","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:57.312429Z","iopub.execute_input":"2021-10-16T17:18:57.313340Z","iopub.status.idle":"2021-10-16T17:18:57.330626Z","shell.execute_reply.started":"2021-10-16T17:18:57.313304Z","shell.execute_reply":"2021-10-16T17:18:57.329553Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"%%capture output\n# capture instruction that saves the result to output \nxgb_params['eta'] = 0.3\nmodel = xgb.train(xgb_params, dtrain,\n                  num_boost_round=100,\n                  evals=watchlist, verbose_eval=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:57.334688Z","iopub.execute_input":"2021-10-16T17:18:57.335043Z","iopub.status.idle":"2021-10-16T17:18:59.577735Z","shell.execute_reply.started":"2021-10-16T17:18:57.335007Z","shell.execute_reply":"2021-10-16T17:18:59.576806Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"tree, p_train, p_val = parse_xgb_output(output)\nprint(f'Eta={xgb_params[\"eta\"]} : Best performance (squarederror, number of trees) ', min(zip(p_val, tree)))\n\nplt.figure(figsize=(6, 4))\nplt.plot(tree, p_train, color='black', linestyle='dashed', label='Train Loss')\nplt.plot(tree, p_val, color='black', linestyle='solid', label='Validation Loss')\n# plt.xticks(range(0, 101, 25))\nplt.legend()\nplt.title('XGBoost: number of trees vs \"squarederror\"')\nplt.xlabel('Number of trees')\nplt.ylabel('squarederror')\nplt.yscale('log')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:18:59.578984Z","iopub.execute_input":"2021-10-16T17:18:59.579234Z","iopub.status.idle":"2021-10-16T17:19:00.029366Z","shell.execute_reply.started":"2021-10-16T17:18:59.579206Z","shell.execute_reply":"2021-10-16T17:19:00.028523Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"%%capture output_010\n# capture instruction that saves the result to output \nxgb_params['eta'] = 0.1\nmodel = xgb.train(xgb_params, dtrain,\n                  num_boost_round=100,\n                  evals=watchlist, verbose_eval=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:19:00.030628Z","iopub.execute_input":"2021-10-16T17:19:00.030859Z","iopub.status.idle":"2021-10-16T17:19:02.408598Z","shell.execute_reply.started":"2021-10-16T17:19:00.030831Z","shell.execute_reply":"2021-10-16T17:19:02.407723Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"tree, _, p_val = parse_xgb_output(output_010)\nprint(f'Eta={xgb_params[\"eta\"]} : Best performance (squarederror, number of trees) ', min(zip(p_val, tree)))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:19:02.410164Z","iopub.execute_input":"2021-10-16T17:19:02.410603Z","iopub.status.idle":"2021-10-16T17:19:02.416568Z","shell.execute_reply.started":"2021-10-16T17:19:02.410552Z","shell.execute_reply":"2021-10-16T17:19:02.415551Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"%%capture output_001\n# capture instruction that saves the result to output \nxgb_params['eta'] = 0.01\nmodel = xgb.train(xgb_params, dtrain,\n                  num_boost_round=100,\n                  evals=watchlist, verbose_eval=10)","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:19:02.418372Z","iopub.execute_input":"2021-10-16T17:19:02.418750Z","iopub.status.idle":"2021-10-16T17:19:04.842818Z","shell.execute_reply.started":"2021-10-16T17:19:02.418700Z","shell.execute_reply":"2021-10-16T17:19:04.841985Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"tree, _, p_val = parse_xgb_output(output_001)\nprint(f'Eta={xgb_params[\"eta\"]} : Best performance (squarederror, number of trees) ', min(zip(p_val, tree)))","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:19:04.846071Z","iopub.execute_input":"2021-10-16T17:19:04.846306Z","iopub.status.idle":"2021-10-16T17:19:04.851266Z","shell.execute_reply.started":"2021-10-16T17:19:04.846280Z","shell.execute_reply":"2021-10-16T17:19:04.850152Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(6, 4))\nfor eta, out in zip([0.3,0.1,0.01],[output,output_010,output_001]):\n    tree, _, p_val = parse_xgb_output(out)\n    #plt.plot(tree, p_train, color='black', linestyle='dashed', label='eta=eta, Train Loss')\n    plt.plot(tree, p_val, linestyle='solid', label=f'eta={eta}')\n    print(f'Eta={eta} : Best performance (squarederror, number of trees) ', min(zip(p_val, tree)))\n    \n# plt.xticks(range(0, 101, 25))\nplt.legend()\nplt.title('XGBoost: number of trees vs Validation \"squarederror\"')\nplt.xlabel('Number of trees')\nplt.ylabel('Validation \"squarederror\"')\n# plt.yscale('log')\nplt.ylim(0.43,0.46)\nplt.grid()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:19:04.852612Z","iopub.execute_input":"2021-10-16T17:19:04.852924Z","iopub.status.idle":"2021-10-16T17:19:05.064651Z","shell.execute_reply.started":"2021-10-16T17:19:04.852880Z","shell.execute_reply":"2021-10-16T17:19:05.063585Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"md(\"### What's the best eta? **0.1**\")","metadata":{"execution":{"iopub.status.busy":"2021-10-16T17:19:05.066385Z","iopub.execute_input":"2021-10-16T17:19:05.066707Z","iopub.status.idle":"2021-10-16T17:19:05.072670Z","shell.execute_reply.started":"2021-10-16T17:19:05.066666Z","shell.execute_reply":"2021-10-16T17:19:05.071769Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}